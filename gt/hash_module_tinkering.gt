--! core/hash.gt except with thoughts about
--! modules down towards the bottom.

const C_ROUNDS: U32 = 2
const D_ROUNDS: U32 = 4

fn rotl(x: U64, b: U64): U64 =
    (x << b) bor (x >> (64 - b))
end

fn u64_from_bytes_le(bytes: U8[] ^): U64 =
    todo("this")
end

fn u64_to_bytes_le(bytes: U64): U8[8] =
    todo("this too")
end

fn sipround(v0: U64, v1: U64, v2: U64, v3: U64): {U64, U64, U64, U64} =
    let v0 = v0 + v1
    let v1 = rotl(v1, 13)
    let v1 = v1 bxor v0
    let v0 = rotl(v0, 32)
    let v2 = v2 + v3;
    let v3 = rotl(v3, 16)
    let v3 = v3 bxor v2
    let v0 = v0 + v3
    let v3 = rotl(v3, 21)
    let v3 = v3 bxor v0
    let v2 = v2 + v1
    let v1 = rotl(v1, 17)
    let v1 = v1 bxor v2
    let v2 = rotl(v2, 32)
    {v0, v1, v2, v3}
end


fn siphash(input: U8 []^, k: U128, out: U8 []^uniq): {} =
    assert(out.len() == 8 or out.len() == 16)
    let mut v0: U64 = 0x736f6d6570736575
    let mut v1: U64 = 0x646f72616e646f6d
    let mut v2: U64 = 0x6c7967656e657261
    let mut v3: U64 = 0x7465646279746573
    -- TODO: Figure out how casts work
    -- Erlang-like bit patterns?
    -- let <<k0:64, k1:64>> = k
    -- Or maybe the bit pattern is an operator that extracts bits
    -- and returns a tuple, and then we define what types those
    -- turn into?
    -- https://www.erlang.org/docs/25/programming_examples/bit_syntax.html#segments
    -- has some info on it, basically we need to say both how many bits
    -- we extract and what type those bits get turned into.
    -- let {k0, k1}: {U64, U64} = <<k0:64, k1:64>> k
    -- let {k0, k1} = <<k0:64/U64, k1:64/U64>> k
    let k0: U64 = (k band 0xFFFF_FFFF) as U32
    let k1: U64 = ((k >> 32) band 0xFFFF_FFFF) as U32
    let left: Size = input.len() band 7
    let mut b: U64 = input.len() << 56
    v3 = v3 bxor k1
    v2 = v2 bxor k0
    v1 = v1 bxor k1
    v0 = v0 bxor k0

    if out.len() == 16 then
        v1 = v1 bxor 0xEE
    end

    -- TODO: This hypothetical `range()` function is `start, end, step` like Python's
    for i in range(0, input.len(), 8) do
        -- TODO: We assume Rust's slice syntax for now?
        let bytes = input[i..(i+8)]
        let m = u64_from_bytes_le(bytes)
        v3 = v3 bxor m
        for _ in range(0,C_ROUNDS) do
            {v0, v1, v2, v3} = sipround(v0, v1, v2, v3)
        end
        v0 = v0 bxor m
    end

    -- Handle the tail 1-7 bytes of the input array.
    -- This is the switch statement in the original code,
    -- I'm just gonna assume we have a compiler that can unroll a loop
    -- for us.
    for i in range(1,8) do
        -- Round input.len() down to the closest multiple of 8
        let input_tail_idx = (input.len() / 8) * 8;
        b = b bor (input[input_tail_idx + i] << i * 8)
    end

    v3 = v3 bxor b

    for _ in range(0, C_ROUNDS) do
        {v0, v1, v2, v3} = sipround(v0, v1, v2, v3)
    end

    v0 = v0 bxor b
    if out.len() == 16 then
        v2 = v2 bxor 0xEE
    else
        v2 = v2 bxor 0xFF
    end

    for _ in range(0, D_ROUNDS) do
        {v0, v1, v2, v3} = sipround(v0, v1, v2, v3)
    end


    -- Oh this is a little weird, out can be either 8 or 16 bytes
    -- and we handle both in this code.  Weird flex but ok?
    let b = v0 bxor v1 bxor v2 bxor v3
    out[..8] = u64_to_bytes_le(b)
    if out == 8 then
        return
    else
        -- Do it again for the high 8 bytes
        v1 = v1 bxor 0xDD
        for _ in range(0, D_ROUNDS) do
            {v0, v1, v2, v3} = sipround(v0, v1, v2, v3)
        end
        let b = v0 bxor v1 bxor v2 bxor v3
        out[8..16] = u64_to_bytes_le(8)
    end
end


--- Should a module def'n look like this?
mod SipHash =
    fn siphash(input: U8 []^, k: U128, out: U8 []^uniq): {}
end

--- Or like this?
mod Hash =
    fn hash(input: U8 []^, k: U128, out: U8 []^uniq): {}
end

--- This module's signature.
type Hash = struct {
    hash: fn(input: U8 []^, k: U128, out: U8 []^uniq): {}
}

--- Equivalent of Rust's `Hasher` trait
---
--- I'll say this explicitly: If we have a `type` type
--- then we can treat it like a normal value, but any
--- actual instances of it must be in `const` only code,
--- which must be able to be evaluated entirely during
--- compilation.
--- This is basically similar to Zig's `comptime`.
---
--- Random thought: wow, I sure wonder what happens if we have a
--- `type[T]` type.
type Hasher = struct {
    Self: type,
    write: fn(self: Self ^uniq, bytes: U8 []^),
    finish: fn(self: Self ^): U64,

    -- For now we are not going to worry about the problem of default
    -- functions.
    write_u8: fn(self: Self ^uniq, i: U8) { ... }
    write_u16: fn(self: Self ^uniq, i: U16) { ... }
    write_u32: fn(self: Self ^uniq, i: U32) { ... }
    write_u64: fn(self: Self ^uniq, i: U64) { ... }
    write_u128: fn(self: Self ^uniq, i: U128) { ... }
    write_size: fn(self: Self ^uniq, i: Size) { ... }
    write_i8: fn(self: Self ^uniq, i: I8) { ... }
    write_i16: fn(self: Self ^uniq, i: I16) { ... }
    write_i32: fn(self: Self ^uniq, i: I32) { ... }
    write_i64: fn(self: Self ^uniq, i: I64) { ... }
    write_i128: fn(self: Self ^uniq, i: I128) { ... }
}

--- The state of our hasher
type SipHasher = struct { }

--- impl Hasher for SipHasher...
---
--- For now I won't try to construct any syntactic sugar at all, just
--- write literally what is going on in the most literal way possible.
---
--- Rust's `self` is MOSTLY syntactic sugar I believe, up until you get
--- into trait objects.
const SIPHASH_IMPL: Hasher = struct {
    Self: SipHasher,
    --- Feed data into hash function
    write: fn(self: Self ^uniq, bytes: U8 []^) =
        ...
    end,

    --- Do the last step of the hash function and return the result
    finish: fn(self: Self ^): U64 =
        ...
    end
}

--- Basic function to take some thing and hash it
fn hash_thing(t: Thing): U64 =
    let thing_bytes: U8[] ^ = magic_as_bytes(thing)
    let hasher: SipHasher ^uniq = SipHasher {} ^uniq
    SIPHASH_IMPL.write(hasher, thing_bytes)
    SIPHASH_IMPL.finish(hasher)
end

--- Ok, that is clunky but perfectly clear, fine.
--- What if we want to hash a thing and a hasher?
--- We have to specify that
fn hash_thing2(hasher: Hasher, t: Thing, hash_state: hasher.Self ^uniq): U64 =
    let thing_bytes: U8[] ^ = magic_as_bytes(thing)
    hasher.write(hash_state, thing_bytes)
    hasher.finish(hash_state)
end

--- Or maybe it looks more rusty with an explicit generic type, like this?
--- This expresses associated types, and kinda does it more
--- comprehensibly than Rust maybe.
fn hash_thing3[HS](hasher: Hasher, t: Thing, hash_state: HS ^uniq): U64
  where HS: hasher.Self =
    let thing_bytes: U8[] ^ = magic_as_bytes(thing)
    hasher.write(hash_state, thing_bytes)
    hasher.finish(hash_state)
end

--- Great, how do we call that?
fn call_hash_thing2(t: Thing): U64 =
    let hash_state = SipHasher {} ^uniq
    hash_thing2(SIPHASH_IMPL, t, hash_state)
    -- Oooooor, theoretically someday we build our API so we can do something like:
    SIPHASH_IMPL:hash_thing3(t, hash_state)
    -- But so far we can NOT do something like this without modifying
    -- SipHasher.
    hash_state:hash_thing(t)
    -- OTOH, ML can include modules in each other's definitions, so it
    -- might be easy to just add your hash_thing function to an extended
    -- Hasher impl...
end

/-
COHERENCE:
Huh, that does allow for two different implementations of the same
module/trait, entertainingly.  You just have to always be explicit
about which one you use.  Maybe not super convenient for like, Add.

The Coherence Problem is bigger than that though.  Basically: imagine
making a hashtable that uses one module for the Hash implementation,
then passing it to a function that uses a different module for its Hash
implementation.  They'll use differnt hash algorithms for the same hash
table and break horribly.  This is discussed here:
https://terbium.io/2021/02/traits-typeclasses/

No, I take it back, coherence isn't a problem for ML modules, because it
does make sure the types have to match up.

Oh, suggestion for turbofish syntax that I actually don't hate: foo.bar.[T]()
this disambiguates with array indexing: foo.bar[some_index]()
Or we could use a real turbofish for the lulz: foo.bar::<T>()
Or the robofish: foo.bar::[T]()



Things to read:
Scala / DOT, Scala implicits,
Original typeclass paper: https://web.engr.oregonstate.edu/~walkiner/teaching/cs583-sp21/files/Wadler-TypeClasses.pdf
Typeclass vs. the world: https://youtu.be/hIZxTQP1ifo
Comparing traits and typeclasses: https://terbium.io/2021/02/traits-typeclasses/
Typeclasses: An exploration of design space: https://www.microsoft.com/en-us/research/wp-content/uploads/1997/01/multi.pdf
MixML: https://people.mpi-sws.org/~rossberg/papers/Rossberg,%20Dreyer%20-%20Mixin'%20Up%20the%20ML%20Module%20System.pdf
F-ing modules: https://people.mpi-sws.org/~rossberg/papers/Rossberg,%20Russo,%20Dreyer%20-%20F-ing%20Modules%20[JFP].pdf
1ML: https://people.mpi-sws.org/~rossberg/papers/Rossberg%20-%201ML%20--%20Core%20and%20modules%20united%20[JFP].pdf

Ok, so reasons I want to do modules instead of typeclasses/traits:

 * Unification of everything-is-a-struct
 * Typeclass/trait metaprogramming gets hairy af
 * Still able to compile to static dispatch

Key points from typeclass vs. the world:

 * Typeclasses can be done with static dispatch (though the original
   paper kinda implied dynamic dispatch)
 * Rust's Self is just syntactic sugar
 * The annoying `impl<T> MyTrait for T {}` syntax may be avoidable by
   decorating type variables so you know they're type variables;
   `impl MyTrait for @T {}`
 * Best description I've seen of generics vs associated types in traits:
   Generics are types set by the caller, associated types are types set
   by the impl.  You can kinda do without them but it gets damn
   squirrelly.  Haskell doesn't have em, but there's a couple different
   extensions that do something similar.
 * Having generics in associated types gets you into higher-kinded types


-/

-- FINE let's just implement a simple lookup table thing and see what happens.

--- Trait Eq
--- We don't bother with PartialEq atm
type EQ = struct {
    -- Rust's PartialEq trait lets Lhs and Rhs to be different,
    -- but by default they are the same so we're gonna do that
    -- because it makes the Map module simpler
    --Lhs: type,
    --Rhs: type,
    Self: type,
    eq: fn(lhs: Self ^, rhs: Self ^): Bool,
    ne: fn(lhs: Self ^, rhs: Self ^): Bool = not eq(rhs, lhs) end,
}

--- From 1ML paper page 11
--- "trait definition" for associative array
type MAP = struct {
    Key: type,
    Map[Val]: type,
    empty[Val]: fn(): Map[Val],
    lookup[Val]: fn(Map[Val] ^, Key): Option[Val],
    add[Val]: fn(Map[Val] ^uniq, Key, Val),
}

--- Implementation...
--- Their signature is `Map (Key : EQ) :> MAP where (type .key = Key.t)`
--- and the .key = Key.t seems redundant with what we're already
--- writing?
---
--- They apparently define a "map" that is just a cell of one value,
--- which doesn't seem very useful to me, so I'm gonna write it to be
--- an assoc list in a theoretical Vec type, and make it more Rusty with
--- mutable references and such.
/-
Similarly, MAP defines a signature with abstract key and map types. The Map function is
a functor: it takes a value of type EQ, i.e., a module. From that it constructs a naive imple-
mentation of maps. “X:>T ” is the usual sealing operator that opaquely ascribes a type (i.e.,
signature) to a value (here, a module). The type refinement syntax “T where (type .X=T )”
should be familiar from ML, but here it actually is derived from a more general construct:
“T where (.X:U)” refines T ’s subcomponent at path .X to type U, which can be any
subtype of what’s declared by T . That form subsumes module sharing as well as other
forms of refinement, with some appropriate sugar defined in Figure 2.
-/
const Map[Key]: MAP where Key: EQ = struct {
    Key: type = Key.Self,
    Map[Val]: type = Vec[{Key,Val}],

    empty[Val]: fn(): Map[Val] = Vec.empty() end,

    lookup[Val]: fn(map: Map[Val]^, ky: Key): Option[Val] =
        for {k,v} in map do
            if Key.eq(k, ky) then return Some(v) end
        end
        None
    end,

    add[Val]: fn(map: Map[Val]^uniq, ky: Key, vl: Val) =
        -- Don't bother with duplicates
        Vec.insert(map, {ky, vl})
    end,
}

--- Ok but as it says that is actually a functor, so we
--- need to make it a function and not a fixed thing.
--- The type variable in the const decl is a clue, I guess.
--- For now we'll just call it a const function
--- and assume that's enough.
---
--- This breaks my brain a little 'cause it doesn't mention
--- freakin' ANYTHING about definining what type the value is,
--- it's just there.
---const Map[Key]: MAP where Key: EQ = struct {
const fn Map[Val](Key: EQ): MAP[Val] =
    struct {
        Key: type = Key.Self,
        Map[Val]: type = Vec[{Key,Val}],

        empty[Val] = fn(): Map[Val] = Vec.empty() end,

        lookup[Val] = fn(map: Map[Val]^, ky: Key): Option[Val] =
            for {k,v} in map do
                if Key.eq(k, ky) then return Some(v) end
            end
            None
        end,

        add[Val] = fn(map: Map[Val]^uniq, ky: Key, vl: Val) =
            -- Don't bother with duplicates
            Vec.insert(map, {ky, vl})
        end,
    }
end

fn actually_use_it_i_guess(): {} =
    -- Instantiate the module
    -- Hmm, we need an implementation of Eq for I32, that's an
    -- iiiiinteresting problem to represent...
    -- Do we have an I32.Eq impl?
    -- Do we have an Eq.I32 impl?
    -- Part of my annoyance with Rust is that the f32 modules and
    -- types are not the same thing, and here I am running into
    -- the same problem...
    -- I suppose part of my goal with this whole jazz is to make
    -- modules and types the same thing, so...
    const M: Map[String] = Map(I32.EQ)
    -- Actually do stuff with it
    let my_map: Map[String]^uniq = m.empty() ^uniq
    M.add(my_map, 1, "foo")
    M.add(my_map, 2, "bar")
    assert_eq(M.lookup(my_map, 1), "foo")
end

